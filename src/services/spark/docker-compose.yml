version: "3.8"
services:
  spark-master:
    image: bitnami/spark:3.5.0
    env_file:
      - ../../.env
    environment:
      - SPARK_MODE=master
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
      - OTEL_SERVICE_NAME=spark-master
      - OTEL_RESOURCE_ATTRIBUTES=service.name=spark-master,deployment.environment=production
    configs:
      - source: spark_defaults
        target: /opt/bitnami/spark/conf/spark-defaults.conf
      - source: spark_metrics
        target: /opt/bitnami/spark/conf/metrics.properties
    secrets:
      - source: ssl_cert
        target: /opt/bitnami/spark/conf/cert.pem
      - source: ssl_key
        target: /opt/bitnami/spark/conf/key.pem
    ports:
      - "8080:8080" # Web UI
      - "8443:8443" # Web SSL
      - "7077:7077" # Spark master port
    networks:
      - etl_network
    volumes:
      - spark_data:/bitnami
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "{{.Name}}/{{.ID}}"
        labels: "service=spark"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      # restart_policy:
      #   condition: on-failure
      # resources:
      #   limits:
      #     cpus: "1"
      #     memory: 1G
      #   reservations:
      #     cpus: "0.5"
      #     memory: 512M

  # Spark worker nodes
  spark-worker:
    image: bitnami/spark:3.5.0
    env_file:
      - ../../.env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
      - OTEL_SERVICE_NAME=spark-worker
      - OTEL_RESOURCE_ATTRIBUTES=service.name=spark-worker,deployment.environment=production
    configs:
      - source: spark_defaults
        target: /opt/bitnami/spark/conf/spark-defaults.conf
      - source: spark_metrics
        target: /opt/bitnami/spark/conf/metrics.properties
    secrets:
      - source: ssl_cert
        target: /opt/bitnami/spark/conf/cert.pem
      - source: ssl_key
        target: /opt/bitnami/spark/conf/key.pem
    ports:
      - "7080:8080" # Worker Web UI
      - "7443:8443" # Worker SSL
    networks:
      - etl_network
    volumes:
      - spark_worker_data:/bitnami
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "{{.Name}}/{{.ID}}"
        labels: "service=spark"
    deploy:
      mode: replicated
      replicas: 1 # Start with 2 workers, adjust based on your needs
      placement:
        constraints:
          - node.role == worker
        preferences:
          - spread: node.id
      # restart_policy:
      #   condition: on-failure
      # resources:
      #   limits:
      #     cpus: "1"
      #     memory: 1G
      #   reservations:
      #     cpus: "0.5"
      #     memory: 512M

  # Spark History Server for job history and logs
  spark-history-server:
    image: bitnami/spark:3.5.0
    command:
      - /opt/bitnami/spark/sbin/start-history-server.sh
    env_file:
      - ../../.env
    environment:
      - SPARK_MODE=master # Using master mode for the history server
      - SPARK_HISTORY_FS_LOG_DIRECTORY=file:///spark-logs
    configs:
      - source: spark_defaults
        target: /opt/bitnami/spark/conf/spark-defaults.conf
    ports:
      - "6080:8080" # History Server UI
      - "6443:8443" # History Server SSL
    networks:
      - etl_network
    volumes:
      - spark_history_data:/spark-logs
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        tag: "{{.Name}}/{{.ID}}"
        labels: "service=spark"
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      # resources:
      #   limits:
      #     cpus: "0.25"
      #     memory: 256M
      #   reservations:
      #     cpus: "0.1"
      #     memory: 128M

networks:
  etl_network:
    external: true

volumes:
  spark-data:
    driver: local
    name: spark-data
  spark-worker-data:
    driver: local
    name: spark-worker-data
  spark_history_data:
    driver: local
    name: spark-history-data

configs:
  spark_defaults:
    file: ./conf/spark-defaults.conf
  spark_metrics:
    file: ./conf/metrics.properties

secrets:
  ssl_cert:
    file: ../../secrets/fullchain.pem
  ssl_key:
    file: ../../secrets/privkey.pem
