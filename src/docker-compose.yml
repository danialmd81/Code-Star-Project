version: "3.8"

services:
  # -----------------------------------------------
  # Backend
  # -----------------------------------------------
  # -----------------------------------------------
  # Database
  # -----------------------------------------------
  database:
    image: postgres:15-alpine
    env_file:
      - .env
    volumes:
      - database_data:/var/lib/postgresql/data
    configs:
      - source: init_script
        target: /docker-entrypoint-initdb.d/01-init.sql
    networks:
      - etl-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 5s
      retries: 5
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
      # restart_policy:
      #   condition: on-failure
      #   delay: 5s
      #   max_attempts: 3
      #   window: 120s

  backup:
    image: prodrigestivill/postgres-backup-local
    environment:
      POSTGRES_HOST: database
      POSTGRES_DB: ${POSTGRES_DB:-etl_db}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    volumes:
      - ./backups:/backups
    networks:
      - etl-network
    depends_on:
      - database
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
      # restart_policy:
      #   condition: on-failure
      #   delay: 5s
      #   max_attempts: 3
      #   window: 120s

  replica:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-etl_db}
      POSTGRES_USER: ${POSTGRES_USER:-replica}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-replica_pass}
    volumes:
      - replica_data:/var/lib/postgresql/data
    configs:
      - source: replica_init_script
        target: /docker-entrypoint-initdb.d/01-replica-init.sql
    networks:
      - etl-network
    depends_on:
      - database
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G

  etcd:
    image: quay.io/coreos/etcd:v3.5.0
    command: etcd -name etcd0 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379
    ports:
      - "2379:2379"
    networks:
      - etl-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G

  patroni:
    image: zalando/patroni:latest
    environment:
      PATRONI_SCOPE: etl-cluster
      PATRONI_NAME: node1
      PATRONI_RESTAPI_LISTEN: 0.0.0.0:8008
      PATRONI_ETCD_HOSTS: etcd:2379
      PATRONI_POSTGRESQL_DATA_DIR: /var/lib/postgresql/data
      PATRONI_POSTGRESQL_PASSWORD: postgres
      PATRONI_POSTGRESQL_SUPERUSER_PASSWORD: postgres
      PATRONI_POSTGRESQL_REPLICATION_PASSWORD: rep_pass
    volumes:
      - patroni_data:/var/lib/postgresql/data
    networks:
      - etl-network
    depends_on:
      - etcd
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G

  # -----------------------------------------------
  # Frontend
  # -----------------------------------------------
  # -----------------------------------------------
  # Keycloak
  # -----------------------------------------------
  keycloak:
    image: quay.io/keycloak/keycloak:26.3
    command:
      - start
      - --import-realm
      - --proxy-headers=xforwarded
      # - --hostname-debug=true
    depends_on:
      - database
    env_file:
      - .env
    environment:
      # JVM settings
      JAVA_OPTS_APPEND: >-
        -Xms1g -Xmx2g
        -XX:MetaspaceSize=96m
        -XX:MaxMetaspaceSize=256m
        -XX:+ParallelRefProcEnabled
        -XX:+UseStringDeduplication
        -Djava.net.preferIPv4Stack=true
    volumes:
      - keycloak_themes:/opt/keycloak/themes
    configs:
      - source: team1_realm
        target: /opt/keycloak/data/import/team1_realm.json
      - source: team2_realm
        target: /opt/keycloak/data/import/team2_realm.json
      - source: team3_realm
        target: /opt/keycloak/data/import/team3_realm.json
    secrets:
      - ssl_cert
      - ssl_key
    ports:
      - "8080:8080"
      - "8443:8443"
    networks:
      - etl-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 3G
        reservations:
          cpus: "1"
          memory: 2G
      # restart_policy:
      #   condition: on-failure

  # -----------------------------------------------
  # Monitoring
  # -----------------------------------------------
  node-exporter:
    image: prom/node-exporter:v1.6.0
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--path.rootfs=/rootfs"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    ports:
      - "9100:9100"
    networks:
      - etl-network
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "-q",
          "--tries=1",
          "--spider",
          "http://localhost:9100/metrics",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      mode: global
      placement:
        constraints:
          - node.platform.os == linux
      # restart_policy:
      # condition: on-failure
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  cadvisor:
    image: bitnami/cadvisor:0.53.0
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
    privileged: true
    # TODO #23 find a way to use cadvisor without root
    user: root
    userns_mode: host
    ports:
      - "8080:8080"
    networks:
      - etl-network
    deploy:
      mode: global
      placement:
        constraints:
          - node.platform.os == linux
      # restart_policy:
      # condition: on-failure

  otel-collector:
    image: otel/opentelemetry-collector:0.132.0
    command: ["--config=/etc/otelcol/config.yaml"]
    configs:
      - source: otel_collector_config
        target: /etc/otelcol/config.yaml
    networks:
      - etl-network
    ports:
      - "8889:8889" # Prometheus exporter endpoint
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
      - "13133:13133" # Health check endpoint

  prometheus:
    image: prom/prometheus:v3.5.0
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
    configs:
      - source: prometheus_config
        target: /etc/prometheus/prometheus.yml
    volumes:
      - prometheus-data:/prometheus
    networks:
      - etl-network
    ports:
      - "9090:9090"
    depends_on:
      - otel-collector
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "-q",
          "--tries=1",
          "--spider",
          "http://localhost:9090/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  loki:
    image: grafana/loki:3.1.0
    command: -config.file=/etc/loki/local-config.yaml
    configs:
      - source: loki_config
        target: /etc/loki/local-config.yaml
    volumes:
      - loki-data:/loki
    networks:
      - etl-network
    ports:
      - "3100:3100"
    # healthcheck:
    #   test:
    #     [
    #       "CMD",
    #       "wget",
    #       "-q",
    #       "--tries=1",
    #       "--spider",
    #       "http://localhost:3100/ready",
    #     ]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
    #   start_period: 30s

  promtail:
    image: grafana/promtail:2.9.3
    command: -config.file=/etc/promtail/promtail-config.yaml
    configs:
      - source: promtail_config
        target: /etc/promtail/promtail-config.yaml
    volumes:
      - /var/log:/var/log:ro
    networks:
      - etl-network
    # ports:
    # - "9080:9080" # Promtail ready endpoint (optional, for health checks)
    depends_on:
      - loki

  grafana:
    image: grafana/grafana:11.5
    # configs:
    # - source: grafana_provisioning_1
    # target: /etc/grafana/provisioning/file
    # - source: grafana_dashboards_1
    # target: /var/lib/grafana/dashboards/file.json
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - etl-network
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
      - loki
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "-q",
          "--tries=1",
          "--spider",
          "http://localhost:3000/api/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  alertmanager:
    image: prom/alertmanager:v0.26.0
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
      - "--storage.path=/alertmanager"
    # configs:
    # - source: alertmanager_config
    # target: /etc/alertmanager/alertmanager.yml
    networks:
      - etl-network
    ports:
      - "9093:9093"
    depends_on:
      - prometheus
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "-q",
          "--tries=1",
          "--spider",
          "http://localhost:9093/-/healthy",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
  # -----------------------------------------------
  # Nginx
  # -----------------------------------------------
  nginx:
    image: nginx:stable-alpine
    depends_on:
      - keycloak
    env_file:
      - .env
    configs:
      - source: nginx_conf
        target: /etc/nginx/nginx.conf
      - source: keycloak.conf
        target: /etc/nginx/conf.d/keycloak.conf
    secrets:
      - ssl_cert
      - ssl_key
    ports:
      - "80:80"
      - "443:443"
    networks:
      - etl-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 128M
      # restart_policy:
      #   condition: on-failure

  # -----------------------------------------------
  # Spark
  # -----------------------------------------------
  spark-master:
    image: bitnami/spark:3.5.0
    env_file:
      - .env
    environment:
      - SPARK_MODE=master
    # ports:
    #   - "8080:8080" # Web UI
    #   - "7077:7077" # Spark master port
    configs:
      - source: spark-defaults
        target: /opt/bitnami/spark/conf/spark-defaults.conf
      - source: spark-metrics
        target: /opt/bitnami/spark/conf/metrics.properties
    volumes:
      - spark-data:/bitnami
      # TODO #21 find a way for binding ./data in docker swarm cluster
      - ./data:/data
    networks:
      - etl-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == worker
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
      # restart_policy:
      #   condition: on-failure

  # Spark worker nodes
  spark-worker:
    image: bitnami/spark:3.5.0
    depends_on:
      - spark-master
    env_file:
      - .env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    # ports:
    #   - "8081:8081" # Worker Web UI
    volumes:
      - spark-worker-data:/bitnami
      # TODO #21 find a way for binding ./data in docker swarm cluster
      - ./data:/data
    networks:
      - etl-network
    deploy:
      mode: replicated
      replicas: 2 # Start with 2 workers, adjust based on your needs
      placement:
        constraints:
          - node.role == worker
          - node.labels.compute == high
        preferences:
          - spread: node.id
      resources:
        limits:
          cpus: "2"
          memory: 3G
        reservations:
          cpus: "1"
          memory: 2G
      # restart_policy:
      #   condition: on-failure

    # Spark History Server for job history and logs
    spark-history-server:
      image: bitnami/spark:3.5.0
      command:
        - /opt/bitnami/spark/sbin/start-history-server.sh
      env_file:
        - .env
      environment:
        - SPARK_MODE=master # Using master mode for the history server
        - SPARK_HISTORY_FS_LOG_DIRECTORY=file:///spark-logs
      # ports:
      #   - "18080:18080" # History Server UI
      configs:
        - source: spark-defaults
          target: /opt/bitnami/spark/conf/spark-defaults.conf
      volumes:
        # TODO #21 find a way for binding ./data in docker swarm cluster
        - ./spark-logs:/spark-logs
      networks:
        - etl-network
      deploy:
        placement:
          constraints:
            - node.role == worker
        resources:
          limits:
            cpus: "0.5"
            memory: 1G
          reservations:
            cpus: "0.2"
            memory: 512M

# -----------------------------------------------
# Networks
# -----------------------------------------------
networks:
  etl-network:
    driver: overlay
    attachable: true
    name: etl-network

# -----------------------------------------------
# Volumes
# -----------------------------------------------
volumes:
  database_data:
    driver: local
    name: database_data
  replica_data:
    driver: local
    name: replica_data
  patroni_data:
    driver: local
    name: patroni_data

  frontend_data:
    driver: local
    name: frontend_data

  keycloak_themes:
    driver: local
    name: keycloak_themes

  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  loki-data:
    driver: local
    name: loki_data

  spark-data:
    driver: local
    name: spark_data
  spark-worker-data:
    driver: local
    name: spark_worker_data

# -----------------------------------------------
# Secrets
# -----------------------------------------------
secrets:
  ssl_cert:
    file: ./secrets/fullchain.pem
  ssl_key:
    file: ./secrets/privkey.pem
# -----------------------------------------------
# Configs
# -----------------------------------------------
configs:
  init_script:
    file: ./services/database/init/01-init.sql
  replica_init_script:
    file: ./services/database/replica-init/01-replica-init.sql

  etl_project_realm:
    file: ./services/keycloak/realm-config/etl-project-realm.json
  team1_realm:
    file: ./services/keycloak/realm-config/team1-realm.json
  team2_realm:
    file: ./services/keycloak/realm-config/team2-realm.json
  team3_realm:
    file: ./services/keycloak/realm-config/team3-realm.json

  otel_collector_config:
    file: ./services/monitoring/otel-collector/config.yaml
  prometheus_config:
    file: ./services/monitoring/prometheus/prometheus.yml
  promtail_config:
    file: ./services/monitoring/promtail/promtail.yaml
  loki_config:
    file: ./services/monitoring/loki/local-config.yaml
  grafana_provisioning_1:
    file: ./services/monitoring/grafana/provisioning/file
  grafana_dashboards_1:
    file: ./services/monitoring/grafana/dashboards/file.json
  alertmanager_config:
    file: ./services/monitoring/alertmanager/alertmanager.yml

  nginx_conf:
    file: ./services/nginx/nginx.conf
  keycloak.conf:
    file: ./services/nginx/conf.d/keycloak.conf

  spark-defaults:
    file: ./services/spark/conf/spark-defaults.conf
  spark-metrics:
    file: ./services/spark/conf/metrics.properties
